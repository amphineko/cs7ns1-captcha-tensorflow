{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rVIiIQJed3G",
        "outputId": "42f033c4-ab7c-48fc-f4d8-537c3813bd68"
      },
      "outputs": [],
      "source": [
        "!pip3 install -U captcha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIriD6gaqZhm"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KD94Se6cbzq"
      },
      "outputs": [],
      "source": [
        "from captcha.image import ImageCaptcha\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "# captcha label setup\n",
        "\n",
        "symbols = ' ' + ''.join(sorted(string.ascii_uppercase + string.ascii_lowercase + string.digits + '#%-:<>[]{}'))\n",
        "\n",
        "captcha_lens = [1, 2, 3, 4, 5, 6]\n",
        "captcha_max_len = 8\n",
        "\n",
        "# captcha image setup\n",
        "\n",
        "img_height, img_width = 64, 128\n",
        "\n",
        "# utility functions\n",
        "\n",
        "decode_label = lambda s: ''.join([symbols[x] for x in s[:s.index(0)]])\n",
        "encode_label = lambda s: [symbols.find(x) for x in s.ljust(captcha_max_len)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDR53dulg5v2"
      },
      "source": [
        "## Sample Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "8mfZ8kN8c4bS",
        "outputId": "18101546-29dc-4d7a-a4cb-c82fa338b052"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, len_batch, n_batch, img_height, img_width, symbols, encode_label, max_len_label, lens_label):\n",
        "        self.len_batch = len_batch\n",
        "        self.n_batch = n_batch\n",
        "\n",
        "        self.height, self.width = img_height, img_width\n",
        "\n",
        "        self.symbols = symbols\n",
        "        self.n_symbols = len(symbols)\n",
        "        self.encode_label = encode_label\n",
        "\n",
        "        self.max_len_label = max_len_label\n",
        "        self.lens_label = lens_label\n",
        "\n",
        "        self.generator = ImageCaptcha(img_width, img_height)\n",
        "\n",
        "        self.cache = [None for _ in range(n_batch)]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.n_batch\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.cache[idx] != None:\n",
        "            return self.cache[idx]\n",
        "        \n",
        "        inputs = np.zeros((self.len_batch, self.width, self.height, 1), dtype=np.float32)\n",
        "        labels = np.zeros((self.len_batch, self.max_len_label,), dtype=np.int64)\n",
        "\n",
        "        avail_symbols = self.symbols[1:]\n",
        "\n",
        "        for i in range(self.len_batch):\n",
        "            text = ''.join([random.choice(avail_symbols) for _ in range(random.choice(self.lens_label))])\n",
        "\n",
        "            img = self.generator.generate_image(text)\n",
        "            img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "            # _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "            # kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
        "            # img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "            img = img / 255.0\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            img = img.transpose(1, 0, 2) \n",
        "            inputs[i] = img\n",
        "\n",
        "            labels[i] = encode_label(text)\n",
        "        \n",
        "        self.cache[idx] = {\n",
        "            \"image\": inputs, \n",
        "            \"label\": labels,\n",
        "        }\n",
        "\n",
        "        return self.cache[idx]\n",
        "    \n",
        "    def reset(self):\n",
        "        self.cache = [None for _ in range(self.n_batch)]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        random.shuffle(self.cache)\n",
        "\n",
        "def print_example_dataset_row():\n",
        "    from google.colab.patches import cv2_imshow\n",
        "\n",
        "    dataset = DataGenerator(\n",
        "                            len_batch=4,\n",
        "                            n_batch=1,\n",
        "                            img_width=img_width,\n",
        "                            img_height=img_height,\n",
        "                            symbols=symbols,\n",
        "                            encode_label=encode_label,\n",
        "                            max_len_label=captcha_max_len,\n",
        "                            lens_label = captcha_lens,\n",
        "                            )\n",
        "    \n",
        "    batch = dataset.__getitem__(0)\n",
        "\n",
        "    for i in range(len(batch['image'])):\n",
        "        img = batch['image'][i].transpose(1, 0, 2) * 255.0\n",
        "        cv2_imshow(img)\n",
        "\n",
        "        label = decode_label([int(x) for x in batch['label'][i]])\n",
        "        print(label)\n",
        "\n",
        "print_example_dataset_row()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v94zUOmg3mo"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtgiulGsVhJi"
      },
      "outputs": [],
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "def build_model(len_label_max, n_symbols):\n",
        "    input = layers.Input(shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\")\n",
        "    label = layers.Input(name=\"label\", shape=(len_label_max,), dtype=\"int64\")\n",
        "\n",
        "    x = input\n",
        "\n",
        "    # cnn module\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), name='max1')(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), name='max2')(x)\n",
        "\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(1, 2), name='max3')(x)\n",
        "\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same', name='conv6')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(1, 2), name='max4')(x)\n",
        "\n",
        "    x = layers.Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    \n",
        "    model = keras.Model(input, x, name='cnn')\n",
        "    x = model(input)\n",
        "\n",
        "    # bridging\n",
        "\n",
        "    conv_shape = x.get_shape()\n",
        "    x = layers.Reshape((int(conv_shape[1]), int(conv_shape[3] * conv_shape[2])))(x)\n",
        "\n",
        "    x = layers.Dense(32)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # rnn module\n",
        "\n",
        "    rnn_size = 128\n",
        "\n",
        "    x = layers.Bidirectional(layers.GRU(rnn_size, kernel_initializer='he_normal', return_sequences=True))(x)\n",
        "    x = layers.Bidirectional(layers.GRU(rnn_size, kernel_initializer='he_normal', return_sequences=True))(x)\n",
        "\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.Dense(n_symbols + 1, kernel_initializer='he_normal', activation='softmax')(x)\n",
        "\n",
        "    # prediction model\n",
        "\n",
        "    predict_model = keras.Model(input, x)\n",
        "\n",
        "    # ctc loss\n",
        "\n",
        "    loss_out = CTCLayer(name='ctc_loss')(label, x)\n",
        "\n",
        "    # training model\n",
        "\n",
        "    model = keras.Model(inputs=[input, label], outputs=loss_out)\n",
        "    model.compile(optimizer=keras.optimizers.Adam())\n",
        "\n",
        "    return model, predict_model\n",
        "\n",
        "\n",
        "model, predict_model = build_model(len_label_max=captcha_max_len, n_symbols=len(symbols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCQIKx1jdeVo"
      },
      "outputs": [],
      "source": [
        "# model.summary()\n",
        "# predict_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpeGQ-EagV6_"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkaMwpP0fD8-"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "checkpoint = Path('/content/drive/MyDrive/CS7NS1/ctc.h5')\n",
        "rescue = Path('/content/drive/MyDrive/CS7NS1/ctc.rescue.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2KwcA13qehz"
      },
      "outputs": [],
      "source": [
        "if checkpoint.is_file():\n",
        "    model.load_weights(checkpoint)\n",
        "    print('Loaded checkpoint from %s' % (checkpoint.name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1VDddpfe6Ps",
        "outputId": "fc70a20a-0a70-4d38-840a-dd1fcf2f9d59"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "model_callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                  patience=5,\n",
        "                                  restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(checkpoint, save_best_only=True),\n",
        "]\n",
        "\n",
        "device = tf.device('/cpu:0')\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Using GPU at: %s' % (device_name))\n",
        "    device = tf.device(device_name)\n",
        "\n",
        "training_dataset = DataGenerator(len_batch=32, n_batch=256, \n",
        "                                 img_width=img_width, img_height=img_height, \n",
        "                                 symbols=symbols,\n",
        "                                 encode_label=encode_label,\n",
        "                                 max_len_label=captcha_max_len,\n",
        "                                 lens_label=captcha_lens)\n",
        "\n",
        "validation_dataset = DataGenerator(len_batch=32, n_batch=16, \n",
        "                                   img_width=img_width, img_height=img_height, \n",
        "                                   symbols=symbols,\n",
        "                                   encode_label=encode_label,\n",
        "                                   max_len_label=captcha_max_len,\n",
        "                                   lens_label=captcha_lens)\n",
        "\n",
        "with device:\n",
        "    for _ in range(5):\n",
        "        training_dataset.reset()\n",
        "        validation_dataset.reset()\n",
        "\n",
        "        try:\n",
        "            model.fit(training_dataset,\n",
        "                      validation_data=validation_dataset,\n",
        "                      epochs=100,\n",
        "                      callbacks=[model_callbacks],\n",
        "                      workers=multiprocessing.cpu_count())\n",
        "        except KeyboardInterrupt:\n",
        "            model.save(rescue)\n",
        "            print('Stopped by keyboard interrupt')\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCBUHVDxgRtD"
      },
      "source": [
        "## Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2343_fLD8UQ"
      },
      "outputs": [],
      "source": [
        "def decode_prediction(y_pred):\n",
        "    input_length = np.ones(y_pred.shape[0]) * y_pred.shape[1]\n",
        "    y_pred = keras.backend.ctc_decode(y_pred, input_length, greedy=False)[0][0][:, :captcha_max_len]\n",
        "    y_pred = [decode_label(list(y)) for y in y_pred]\n",
        "    return y_pred\n",
        "\n",
        "def benchmark():\n",
        "    prediction_model = predict_model\n",
        "\n",
        "    dataset = DataGenerator(len_batch=1000, n_batch=1, \n",
        "                                       img_width=img_width, img_height=img_height, \n",
        "                                       symbols=symbols,\n",
        "                                       encode_label=encode_label,\n",
        "                                       max_len_label=captcha_max_len,  \n",
        "                                       lens_label=captcha_lens)\n",
        "\n",
        "    batch = dataset.__getitem__(0)\n",
        "    batch_size = len(batch['image'])\n",
        "\n",
        "    x = batch['image']\n",
        "    x = x.reshape((-1, 128, 64, 1))\n",
        "\n",
        "    y_true = batch['label']\n",
        "    y_true = [decode_label(list(y)) for y in y_true]\n",
        "\n",
        "    y_pred = prediction_model.predict(x)\n",
        "    y_pred = decode_prediction(y_pred)\n",
        "\n",
        "    correct = 0\n",
        "    for i, _ in enumerate(x):\n",
        "        true, pred = y_true[i], y_pred[i]\n",
        "        if true == pred:\n",
        "            correct = correct + 1\n",
        "        else:\n",
        "            print('%d:\\t[%d] %s\\t[%d] %s' % (i, len(true), true.ljust(captcha_max_len), len(pred), pred.ljust(captcha_max_len)))\n",
        "    print('%d of %d are correctly predicted' % (correct, len(x)))\n",
        "\n",
        "\n",
        "benchmark()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnhsXR09Hc3Z"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G5PR5NlHak1",
        "outputId": "bb83cd32-62e1-4d39-fb5f-b8f9b6083d36"
      },
      "outputs": [],
      "source": [
        "!rm -r images images.csv output.csv\n",
        "!tar xf images.tar\n",
        "!ls -ahl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4J-wxJoHgHJ",
        "outputId": "48947022-557f-435c-c0f9-d1a1db047cbe"
      },
      "outputs": [],
      "source": [
        "def batch_predict(model):\n",
        "    parent_path = os.path.abspath('./images')\n",
        "\n",
        "    df = pd.read_csv('./images.csv', header=None, index_col=False, names=['filename'])[['filename']]\n",
        "    df['result'] = ''\n",
        "\n",
        "    start_time = time.time()\n",
        "    for idx, row in df.iterrows():\n",
        "        filename = row['filename']\n",
        "        filename = os.path.join(parent_path, filename)\n",
        "\n",
        "        x = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "        x = xx / 255.0\n",
        "        x = np.expand_dims(x, axis=-1)\n",
        "        x = x.transpose(1, 0, 2) \n",
        "\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        y_pred = model.predict(x)\n",
        "        y_pred = decode_prediction(y_pred)[0]\n",
        "\n",
        "        # print('%s: %s' % (os.path.basename(filename), y_pred))\n",
        "\n",
        "        row['result'] = y_pred\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print('predicted %d of %d images in %f seconds' % (idx, df.shape[0], time.time() - start_time))\n",
        "\n",
        "    print('predicted %d images in %f seconds' % (df.shape[0], time.time() - start_time))\n",
        "    \n",
        "    df.sort_values(by=['filename'], ascending=True)\n",
        "    df.to_csv('./output.csv', columns=['filename', 'result'], header=False, index=False)\n",
        "\n",
        "batch_predict(predict_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_0uJe1rWB3U"
      },
      "source": [
        "## TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOU6kNtpXW0Q"
      },
      "outputs": [],
      "source": [
        "lite_path = Path('/content/drive/MyDrive/CS7NS1/ctc-lite.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH1I7mvoWEOz",
        "outputId": "42dc378e-33c6-490b-83e6-fa495cb72523"
      },
      "outputs": [],
      "source": [
        "def convert_to_tflite(model, quantization='dr'):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    return converter.convert()\n",
        "\n",
        "predict_model.compile(optimizer=keras.optimizers.Adam())\n",
        "predict_model.load_weights(checkpoint)\n",
        "\n",
        "lite_model = convert_to_tflite(predict_model)\n",
        "\n",
        "with open(lite_path, 'wb') as f:\n",
        "    f.write(lite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKUW_0jzbLEf",
        "outputId": "8640a1a8-f113-45bc-87ff-a1cace689aef"
      },
      "outputs": [],
      "source": [
        "!pip3 install -U pyctcdecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNk3xSn5Xw6l",
        "outputId": "9c2fe4b0-2c54-4901-cc3e-61292ca6304f"
      },
      "outputs": [],
      "source": [
        "def decode_ctc_lite(logits, symbols):\n",
        "    output, last_logit = [], None\n",
        "    for logit in logits.argmax(axis=1):\n",
        "        if (logit < len(symbols)) and (logit != last_logit):\n",
        "            output.append(logit)\n",
        "        last_logit = logit\n",
        "\n",
        "    return output\n",
        "\n",
        "def benchmark_lite():\n",
        "    interpreter = tf.lite.Interpreter(model_path=str(lite_path))\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    dataset = DataGenerator(len_batch=1000, n_batch=1, \n",
        "                                       img_width=img_width, img_height=img_height, \n",
        "                                       symbols=symbols,\n",
        "                                       encode_label=encode_label,\n",
        "                                       max_len_label=captcha_max_len,  \n",
        "                                       lens_label=captcha_lens)\n",
        "\n",
        "    batch = dataset.__getitem__(0)\n",
        "    batch_size = len(batch['image'])\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    correct = 0\n",
        "    for i in range(batch_size):\n",
        "        x = batch['image'][i]\n",
        "        y_true = decode_label(list(batch['label'][i]))\n",
        "\n",
        "        x = x.reshape((-1, 128, 64, 1))\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], x)\n",
        "        interpreter.invoke()\n",
        "\n",
        "        y_pred = interpreter.get_tensor(output_details[0]['index'])\n",
        "        y_pred = decode_label(decode_ctc_lite(y_pred[0], symbols))\n",
        "\n",
        "        if y_true == y_pred:\n",
        "            correct = correct + 1\n",
        "        else:\n",
        "            print('%d:\\t[%d] %s\\t[%d] %s' % (i, \n",
        "                                             len(y_true), \n",
        "                                             y_true.ljust(captcha_max_len), \n",
        "                                             len(y_pred), \n",
        "                                             y_pred.ljust(captcha_max_len)))\n",
        "\n",
        "    print('%d of %d are correctly predicted' % (correct, batch_size))\n",
        "\n",
        "\n",
        "benchmark_lite()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfAykhiNfb6E",
        "outputId": "7a732f74-f5a6-4e4b-e327-822b560abd46"
      },
      "outputs": [],
      "source": [
        "def batch_predict_lite():\n",
        "    # lite model setup\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=str(lite_path))\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # read inference list\n",
        "\n",
        "    parent_path = os.path.abspath('./images')\n",
        "\n",
        "    df = pd.read_csv('./images.csv', header=None, index_col=False, names=['filename'])[['filename']]\n",
        "    df['result'] = ''\n",
        "\n",
        "    start_time = time.time()\n",
        "    for idx, row in df.iterrows():\n",
        "        filename = row['filename']\n",
        "        filename = os.path.join(parent_path, filename)\n",
        "\n",
        "        x = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)  # = float64\n",
        "        x = np.array(x, dtype=np.float32) / 255.0       # = float32\n",
        "        x = np.expand_dims(x, axis=-1)                  # = (128, 64)\n",
        "        x = x.transpose(1, 0, 2)                        # = (64, 128, 1)\n",
        "        x = np.expand_dims(x, axis=0)                   # = (1, 128, 64, 1)\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], x)\n",
        "        interpreter.invoke()\n",
        "        y_pred = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "        y_pred = decode_label(decode_ctc_lite(y_pred[0], symbols))\n",
        "\n",
        "        # print('%s: %s' % (os.path.basename(filename), y_pred))\n",
        "\n",
        "        row['result'] = y_pred\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print('predicted %d of %d images in %f seconds' % (idx, df.shape[0], time.time() - start_time))\n",
        "\n",
        "    print('predicted %d images in %f seconds' % (df.shape[0], time.time() - start_time))\n",
        "    \n",
        "    df.sort_values(by=['filename'], ascending=True)\n",
        "    df.to_csv('./output_lite.csv', columns=['filename', 'result'], header=False, index=False)\n",
        "\n",
        "batch_predict_lite()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CS7NS1-CTC.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
